{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mila/g/gagnonju/.main/bin/python\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rich\n",
    "import rich.table\n",
    "import torch\n",
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = rich.table.Table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-29 17:22:59,092] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"gpt2\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16, device_map={\"\": 0}, pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULTS = dict(\n",
    "    max_new_tokens = 70,\n",
    "    do_sample=True,\n",
    "    return_dict=True\n",
    ")\n",
    "\n",
    "def generate(text, **kwargs):\n",
    "    args = DEFAULTS.copy()\n",
    "    args.update(kwargs)\n",
    "    \n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True).to(0)\n",
    "    model_output = model.generate(\n",
    "        **tokens, \n",
    "        **kwargs, \n",
    "        return_dict_in_generate=True, \n",
    "        output_scores=True,\n",
    "    )\n",
    "    gen_seq_len = len(model_output[\"scores\"])\n",
    "    gen_seq = model_output['sequences'][:, -gen_seq_len:]\n",
    "    scores = torch.cat(model_output[\"scores\"]).softmax(-1)\n",
    "    print(f\"{gen_seq_len = }\")\n",
    "    print(f\"{gen_seq.shape = }\")\n",
    "    winning_scores = torch.gather(scores, dim=1, index=gen_seq)\n",
    "    print(f\"{winning_scores.shape = }\")\n",
    "    print(f\"{model_output['sequences'].shape = }\")\n",
    "    return model_output[\"sequences\"][0, -gen_seq_len:], [x.item() for x in winning_scores[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_seq_len = 14\n",
      "gen_seq.shape = torch.Size([1, 14])\n",
      "winning_scores.shape = torch.Size([1, 14])\n",
      "model_output['sequences'].shape = torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "tokens, scores = generate(\"Lol this is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48, 0, 0, 48, 0, 0, 10, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌─────┬──────┬────────┬─────┬──────┬───────┬────┬───┬───┬─────┬───────┬─────┬──────┬───────┐\n",
       "│  of │  the │  power │  of │  the │  mind │ .  │   │   │ The │  mind │  is │  the │  most │\n",
       "│     │      │        │     │      │       │    │   │   │     │       │     │      │       │\n",
       "├─────┼──────┼────────┼─────┼──────┼───────┼────┼───┼───┼─────┼───────┼─────┼──────┼───────┤\n",
       "│ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #e4e4e4\">48</span>  │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c0c0c0\">0</span>    │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c0c0c0\">0</span>      │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #e4e4e4\">48</span>  │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c0c0c0\">0</span>    │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c0c0c0\">0</span>     │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c8c8c8\">10</span> │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c1c1c1\">1</span> │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c1c1c1\">1</span> │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c0c0c0\">0</span>   │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c0c0c0\">0</span>     │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c0c0c0\">0</span>   │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c0c0c0\">0</span>    │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #c0c0c0\">0</span>     │\n",
       "└─────┴──────┴────────┴─────┴──────┴───────┴────┴───┴───┴─────┴───────┴─────┴──────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌─────┬──────┬────────┬─────┬──────┬───────┬────┬───┬───┬─────┬───────┬─────┬──────┬───────┐\n",
       "│  of │  the │  power │  of │  the │  mind │ .  │   │   │ The │  mind │  is │  the │  most │\n",
       "│     │      │        │     │      │       │    │   │   │     │       │     │      │       │\n",
       "├─────┼──────┼────────┼─────┼──────┼───────┼────┼───┼───┼─────┼───────┼─────┼──────┼───────┤\n",
       "│ \u001b[30;48;2;228;228;228m48\u001b[0m  │ \u001b[30;48;2;192;192;192m0\u001b[0m    │ \u001b[30;48;2;192;192;192m0\u001b[0m      │ \u001b[30;48;2;228;228;228m48\u001b[0m  │ \u001b[30;48;2;192;192;192m0\u001b[0m    │ \u001b[30;48;2;192;192;192m0\u001b[0m     │ \u001b[30;48;2;200;200;200m10\u001b[0m │ \u001b[30;48;2;193;193;193m1\u001b[0m │ \u001b[30;48;2;193;193;193m1\u001b[0m │ \u001b[30;48;2;192;192;192m0\u001b[0m   │ \u001b[30;48;2;192;192;192m0\u001b[0m     │ \u001b[30;48;2;192;192;192m0\u001b[0m   │ \u001b[30;48;2;192;192;192m0\u001b[0m    │ \u001b[30;48;2;192;192;192m0\u001b[0m     │\n",
       "└─────┴──────┴────────┴─────┴──────┴───────┴────┴───┴───┴─────┴───────┴─────┴──────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rich.console\n",
    "console = rich.console.Console(width=240)\n",
    "table = rich.table.Table(show_header=False, show_lines=True)\n",
    "print([int(x * 255) for x in scores])\n",
    "\n",
    "def to_col(x):\n",
    "    def to_val(y):\n",
    "        return int(192 * y) + 192\n",
    "\n",
    "    val = to_val(x)\n",
    "    return f\"rgb({val},{val},{val})\"\n",
    "\n",
    "def apply_col(text, score):\n",
    "    return f\"[black on {to_col(score)}]{text}\"\n",
    "\n",
    "\n",
    "table.add_row(*[apply_col(tokenizer.decode(x), score) for x, score in mit.zip_equal(tokens, scores)])\n",
    "table.add_row(*[apply_col(x, x) for x in scores])\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256-64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
