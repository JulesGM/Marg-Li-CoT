{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = transformers.AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "tok.pad_token = tok.eos_token\n",
    "tok.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s><s><s><s> How are you my friend? Lets make this longer</s>', '<s><s><s><s> I am fine</s></s></s></s></s></s></s></s></s>']\n"
     ]
    }
   ],
   "source": [
    "output = tok([\"<s><s><s>How are you my friend? Lets make this longer</s>\", \"<s><s><s>I am fine</s>\"], padding=True, return_tensors=\"pt\")\n",
    "print(tok.batch_decode(output[\"input_ids\"], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "mask_ = tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True])\n",
      "torch.nonzero(mask_, as_tuple=False) = tensor([[15]])\n",
      "end = 16\n",
      "<s><s><s><s> How are you my friend? Lets make this longer</s>\n",
      "\n",
      "################################################################################\n",
      "mask_ = tensor([False, False, False, False, False, False, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True])\n",
      "torch.nonzero(mask_, as_tuple=False) = tensor([[ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10],\n",
      "        [11],\n",
      "        [12],\n",
      "        [13],\n",
      "        [14],\n",
      "        [15]])\n",
      "end = 8\n",
      "<s><s><s><s> I am fine</s>\n"
     ]
    }
   ],
   "source": [
    "mask = output[\"input_ids\"] == tok.pad_token_id\n",
    "start = torch.nonzero(mask, as_tuple=False)\n",
    "\n",
    "for mask_, input_ in zip(mask, output[\"input_ids\"]):\n",
    "    print()\n",
    "    print(\"#\" * 80)\n",
    "    print(f\"{mask_ = }\")\n",
    "    print(f\"{torch.nonzero(mask_, as_tuple=False) = }\")\n",
    "    end = torch.nonzero(mask_, as_tuple=False)[0, 0].item() + 1\n",
    "    print(f\"{end = }\")\n",
    "    \n",
    "    print(tok.decode(input_[:end], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
