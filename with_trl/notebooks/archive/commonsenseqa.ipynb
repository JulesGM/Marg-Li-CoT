{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad\n",
      "/home/mila/g/gagnonju/Marg-Li-CoT/with_trl\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pathlib\n",
    "import itertools\n",
    "import more_itertools\n",
    "import rich\n",
    "import torch\n",
    "import transformers\n",
    "import sys\n",
    "print(pathlib.Path.cwd())\n",
    "print(pathlib.Path.cwd().parent)\n",
    "sys.path.append(str(pathlib.Path.cwd().parent))\n",
    "import libs_data.data_commonsense_qa_few_shot\n",
    "import libs_data.lib_commonsense_qa\n",
    "import lib_trl_utils\n",
    "import bin_main\n",
    "import peft\n",
    "import accelerate\n",
    "\n",
    "FEW_SHOT = libs_data.data_commonsense_qa_few_shot.FEW_SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset commonsense_qa (/home/mila/g/gagnonju/.cache/huggingface/datasets/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question': 'Q: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\\nAnswer Choices:\\n(A) ignore\\n(B) enforce\\n(C) authoritarian\\n(D) yell at\\n(E) avoid\\nA:',\n",
       "  'answer': 'A'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = \"train\"\n",
    "dataset = datasets.load_dataset(\"commonsense_qa\", split=split)\n",
    "batch = [libs_data.lib_commonsense_qa.CommonSenseQAMC._prep_hf_ds(x) for x in itertools.islice(dataset, 1)]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0150af0e9ee640f4993f87d36ac5e65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">):</span> trainable params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8392705</span> || all params: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6746808321</span> || trainable%: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.12439518955766107</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m(\u001b[0m\u001b[1;34m0\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m:\u001b[0m trainable params: \u001b[1;36m8392705\u001b[0m || all params: \u001b[1;36m6746808321\u001b[0m || trainable%: \u001b[1;36m0.12439518955766107\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL_NAME = \"EleutherAI/gpt-j-6B\"\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "DEVICE = 1\n",
    "# model = transformers.AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", torch_dtype=torch.bfloat16).to(1)\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(model.config._name_or_path)\n",
    "peft_config_dict = bin_main.DEFAULT_PEFT_CONFIG.copy()\n",
    "peft_config_dict[\"task_type\"] = peft.TaskType.CAUSAL_LM\n",
    "\n",
    "model, forward_tokenizer, prediction_tokenizer = lib_trl_utils.init_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    use_peft=True,\n",
    "    peft_config_dict=peft_config_dict,\n",
    "    peft_qlora_mode=False,\n",
    "    precision=torch.bfloat16,\n",
    ")\n",
    "DEVICE = 0\n",
    "accelerator = accelerate.Accelerator()\n",
    "model = accelerator.prepare(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'repetition_penalty'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min_new_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'top_k'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'top_p'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'early_stopping'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'synced_gpus'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'do_sample'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_return_sequences'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'max_new_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'repetition_penalty'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'min_new_tokens'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "    \u001b[32m'top_k'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'top_p'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'early_stopping'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'synced_gpus'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'do_sample'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'temperature'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
       "    \u001b[32m'num_return_sequences'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'max_new_tokens'\u001b[0m: \u001b[1;36m200\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'forward_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m keys:\n\u001b[1;32m      9\u001b[0m     unzipped_batch[k] \u001b[39m=\u001b[39m [x[k] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m     11\u001b[0m preped_batch \u001b[39m=\u001b[39m libs_data\u001b[39m.\u001b[39mlib_commonsense_qa\u001b[39m.\u001b[39m_tok_detok(\n\u001b[1;32m     12\u001b[0m     batch\u001b[39m=\u001b[39munzipped_batch,\n\u001b[0;32m---> 13\u001b[0m     any_tokenizer\u001b[39m=\u001b[39mforward_tokenizer, \n\u001b[1;32m     14\u001b[0m     question_prefix\u001b[39m=\u001b[39mFEW_SHOT\u001b[39m.\u001b[39mstrip() \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     15\u001b[0m     question_suffix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m padded \u001b[39m=\u001b[39m prediction_tokenizer\u001b[39m.\u001b[39mpad(\n\u001b[1;32m     19\u001b[0m     \u001b[39mdict\u001b[39m(input_ids\u001b[39m=\u001b[39mpreped_batch[\u001b[39m\"\u001b[39m\u001b[39mquestion_tok\u001b[39m\u001b[39m\"\u001b[39m]), \n\u001b[1;32m     20\u001b[0m     return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     21\u001b[0m     padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m )\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m     24\u001b[0m num_toks \u001b[39m=\u001b[39m padded[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forward_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "gen_kwargs = bin_main.DEFAULT_GEN_KWARGS.copy()\n",
    "gen_kwargs[\"num_return_sequences\"] = 1\n",
    "rich.print(gen_kwargs)\n",
    "batch = [libs_data.lib_commonsense_qa.CommonSenseQAMC._prep_hf_ds(x) for x in itertools.islice(dataset, 1)]\n",
    "keys = batch[0].keys()\n",
    "unzipped_batch = {}\n",
    "\n",
    "for k in keys:\n",
    "    unzipped_batch[k] = [x[k] for x in batch]\n",
    "\n",
    "preped_batch = libs_data.lib_commonsense_qa._tok_detok(\n",
    "    batch=unzipped_batch,\n",
    "    any_tokenizer=forward_tokenizer, \n",
    "    question_prefix=FEW_SHOT.strip() + \"\\n\\n\", \n",
    "    question_suffix=\"\"\n",
    ")\n",
    "\n",
    "padded = prediction_tokenizer.pad(\n",
    "    dict(input_ids=preped_batch[\"question_tok\"]), \n",
    "    return_tensors=\"pt\", \n",
    "    padding=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "num_toks = padded[\"input_ids\"].shape[1]\n",
    "gen_kwargs[\"synced_gpus\"] = False\n",
    "\n",
    "print(padded[\"input_ids\"].shape)\n",
    "print(\"Query: `\" + more_itertools.one(prediction_tokenizer.batch_decode(padded[\"input_ids\"])) + \"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<s> Q: Why do I eat just enough when eating breakfast?\\nAnswer Choices:\\n(A) gas\\n(B) full stomach\\n(C) feeling satisfied (CORRECT)\\n(D) have energy\\n(e) bloated\\nA: The answer must be a reason for eating just enough when eating breakfast. Eating just enough is a way to feel satisfied. Therefore, the answer is feeling satisfied (C).\\n\\nQ: How is a dog likely to communicate with another dog?\\nAnswer Choices:\\n(A) reproduce\\n(B) bark (CORRECT)\\n(C) do many things\\n(D) clone\\n(E) jump up\\nA: The answer must be a way for a dog to communicate with another dog. Dogs bark to communicate with each other. Therefore, the answer is bark (B).\\n\\nQ: If a person is trying to weasel out of punishment for a crime, where are they likely to be?\\nAnswer Choices:\\n(A) court room (CORRECT)\\n(B) cherry tree\\n(C) chicken coop\\n(D) natural history museum\\n(E) jail\\nA: The answer must be a place where a person would be trying to get out of punishment for a crime. The answer is court room (A).\\n\\nQ: What would easily hide a snake?\\nAnswer Choices:\\n(A) living room of a house\\n(B) kew gardens\\n(C) terrarium\\n(D) thick forest (CORRECT)\\n(E) tropical forest\\nA: The answer must be something that would hide a snake. The answer is thick forest (D).\\n\\nQ: The person didnâ€™t like the varying size of the cake slices handed out, she demand more what?\\nAnswer Choices:\\n(A) fairness (CORRECT)\\n(B) candies\\n(C) compliments\\n(D) well fed\\n(E) arguements 2\\nA: The answer must be a reason for the person to demand more cake. The person is not happy with the size of the cake slices. Therefore, the answer is fairness (A).\\n\\nQ: In America, the courthouse of any given town has a likely location, where is it?\\nAnswer Choices:\\n(A) electrical circuit\\n(B) getting married\\n(C) capital city\\n(D) center of town (CORRECT)\\n(E) michigan\\nA: The answer must be a location where a courthouse is located. The capital city is the location of the capital of a state. Therefore, the answer is center of town (D).\\n\\nQ: Where might I find a bowl nestled among other bowls in the kitchen?\\nAnswer Choices:\\n(A) refrigerator\\n(B) kitchen top\\n(C) cupboard (CORRECT)\\n(D) dishwasher\\n(E) apartment\\nA: The answer must be a place where a bowl is found. The kitchen is a place where bowls are found. Therefore, the answer is cupboard (C).\\n\\nQ: Which state has blue ridge mountains that are called Blue Mountain?\\nAnswer Choices:\\n(A) appalachians\\n(B) virginia\\n(C) pennsylvania (CORRECT)\\n(D) north carolina\\n(E) montana A: The answer must be a state with mountains. The answer is Pennsylvania (C).\\n\\nQ: Where could you find many radio studio?\\nAnswer Choices:\\n(A) radio station\\n(B) country\\n(C) clear area\\n(D) office building\\n(E) large city (CORRECT)\\nA: The answer must be a place where many radio studios are located. Radio studios are used to broadcast radio programs. Therefore, the answer is large city (E).\\n\\nQ: Where would someone bring you a cup? \\nAnswer Choices: \\n(A) apartment\\n(B) closet\\n(C) restaurant (CORRECT)\\n(D) table\\n(E) party\\nA: The answer must be a place where someone would bring you a cup. A restaurant is a place where people bring cups. Therefore, the answer is restaurant (C).\\n\\nQ: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\\nAnswer Choices:\\n(A) ignore\\n(B) enforce\\n(C) authoritarian\\n(D) yell at\\n(E) avoid\\nA: The answer must be a way the school seemed to respond to the sanctions. The school seemed to avoid the sanctions. Therefore, the answer is avoid (E).\\n\\nQ:  In an inner city the house numbering _____________\\nAnswer Choices:\\n(A) follow a grid pattern\\n(B) follow a pattern\\n(C) don't follow any pattern\\n(D) are irregular (CORRECT)\\n\\n\\nQ: What is the benefit of aerobic exercise?\\nAnswer Choices:\\n(A) reduce resting metabolic rate\\n(B) increase muscle strength\\n(C) increase bone density\\n(D) improve cardiovascular health (CORRECT)\\n(E) decrease body fat\\nA: The answer must be a benefit of aerobic exercise. Aerobic exercise improves cardiovascular health. Therefore, the answer is improve cardiovascular\"]\n",
      "\n",
      ">>> The answer must be a way the school seemed to respond to the sanctions. The school seemed to avoid the sanctions. Therefore, the answer is avoid (E).\n"
     ]
    }
   ],
   "source": [
    "with model.pretrained_model.disable_adapter():\n",
    "    gen_kwargs[\"repetition_penalty\"] = 1\n",
    "    generated = accelerator.unwrap_model(model).generate(**padded, **gen_kwargs)\n",
    "    num_toks = padded[\"input_ids\"].shape[1]\n",
    "    print(prediction_tokenizer.batch_decode(generated[:, :]))\n",
    "    model = model.eval()\n",
    "    print(\"\\n>>> \" + \"\\n>>> \".join([x.split(\"\\n\", 1)[0] for x in prediction_tokenizer.batch_decode(generated[:, num_toks:])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
