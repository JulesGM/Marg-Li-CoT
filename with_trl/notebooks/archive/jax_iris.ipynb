{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import enum\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "import rich\n",
    "import sklearn.datasets\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_w\n",
      "grad_b\n",
      "Loading digits.\n",
      "Done loading digits.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e75924d21d44fbbb6d05bf3973ab45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step:\n",
      "loss comp: \n",
      "\t - vmap_in_axes = [0, 0, None, None] \n",
      "\t - batch_data.shape = (10, 64) \n",
      "\t - batch_target.shape = (10,) \n",
      "\t - cv_set = <CVSets.TRAIN: 0>\n",
      "batch_target.shape = ()\n",
      "log_softmax.shape = (10,)\n",
      "target.shape = (1,)\n",
      "Grad Desc:\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "(10, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=279'>280</a>\u001b[0m             \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m all_metrics\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=280'>281</a>\u001b[0m                 rich\u001b[39m.\u001b[39mprint(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[bold green](\u001b[39m\u001b[39m{\u001b[39;00mcv_set\u001b[39m}\u001b[39;00m\u001b[39m)[/] Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m: [bold blue]\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m.\u001b[39mtitle()\u001b[39m}\u001b[39;00m\u001b[39m:[/] \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(v)\u001b[39m:\u001b[39;00m\u001b[39m0.2%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=282'>283</a>\u001b[0m train()\n",
      "\u001b[1;32m/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=261'>262</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(dataloaders[cv_set]):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=262'>263</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStep:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=263'>264</a>\u001b[0m     loss, metrics, model_weights, model_biases \u001b[39m=\u001b[39m step(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=264'>265</a>\u001b[0m         batch_data\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=265'>266</a>\u001b[0m         batch_target\u001b[39m=\u001b[39;49mbatch[\u001b[39m\"\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=266'>267</a>\u001b[0m         cv_set\u001b[39m=\u001b[39;49mcv_set,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=267'>268</a>\u001b[0m         model_fn\u001b[39m=\u001b[39;49mmodel_fn,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=268'>269</a>\u001b[0m         model_weights\u001b[39m=\u001b[39;49mmodel_weights,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=269'>270</a>\u001b[0m         model_biases\u001b[39m=\u001b[39;49mmodel_biases,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=270'>271</a>\u001b[0m         learning_mode\u001b[39m=\u001b[39;49mLEARNING_MODE,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=271'>272</a>\u001b[0m         lr\u001b[39m=\u001b[39;49mLEARNING_RATE,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=272'>273</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=273'>274</a>\u001b[0m     \u001b[39massert\u001b[39;00m model_weights\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m, model_weights\u001b[39m.\u001b[39mndim\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=274'>275</a>\u001b[0m     \u001b[39massert\u001b[39;00m model_biases\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, model_biases\u001b[39m.\u001b[39mndim\n",
      "\u001b[1;32m/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=190'>191</a>\u001b[0m \u001b[39mif\u001b[39;00m learning_mode \u001b[39m==\u001b[39m LearningMode\u001b[39m.\u001b[39mGRADIENT_DESCENT:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=192'>193</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGrad Desc:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=193'>194</a>\u001b[0m     model_weights, model_biases \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mtree_map(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=194'>195</a>\u001b[0m         \u001b[39mlambda\u001b[39;49;00m w, b: \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=195'>196</a>\u001b[0m             maybe_vmap(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=196'>197</a>\u001b[0m                 grad_desc(w, b, batch_data, batch_target, lr),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=197'>198</a>\u001b[0m                 out_axes\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=198'>199</a>\u001b[0m                 in_axes\u001b[39m=\u001b[39;49m[\u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m],\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=199'>200</a>\u001b[0m             ),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=200'>201</a>\u001b[0m         model_weights,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=201'>202</a>\u001b[0m         model_biases,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=202'>203</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=204'>205</a>\u001b[0m \u001b[39melif\u001b[39;00m learning_mode \u001b[39m==\u001b[39m LearningMode\u001b[39m.\u001b[39mNEWTON:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=205'>206</a>\u001b[0m     model_weights, model_biases \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_map(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=206'>207</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m weights, biases: \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=207'>208</a>\u001b[0m             newtons(weights, biases, batch_data, batch_target),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=208'>209</a>\u001b[0m         model_weights,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=209'>210</a>\u001b[0m         model_biases,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=210'>211</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.main/lib/python3.9/site-packages/jax/_src/tree_util.py:252\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    250\u001b[0m leaves, treedef \u001b[39m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    251\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m--> 252\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39;49munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;49;00m xs \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mall_leaves))\n",
      "File \u001b[0;32m~/.main/lib/python3.9/site-packages/jax/_src/tree_util.py:252\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m leaves, treedef \u001b[39m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    251\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m--> 252\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;00m xs \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mall_leaves))\n",
      "\u001b[1;32m/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=190'>191</a>\u001b[0m \u001b[39mif\u001b[39;00m learning_mode \u001b[39m==\u001b[39m LearningMode\u001b[39m.\u001b[39mGRADIENT_DESCENT:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=192'>193</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGrad Desc:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=193'>194</a>\u001b[0m     model_weights, model_biases \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_map(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=194'>195</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m w, b: \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=195'>196</a>\u001b[0m             maybe_vmap(\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=196'>197</a>\u001b[0m                 grad_desc(w, b, batch_data, batch_target, lr),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=197'>198</a>\u001b[0m                 out_axes\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=198'>199</a>\u001b[0m                 in_axes\u001b[39m=\u001b[39m[\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39mNone\u001b[39;00m],\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=199'>200</a>\u001b[0m             ),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=200'>201</a>\u001b[0m         model_weights,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=201'>202</a>\u001b[0m         model_biases,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=202'>203</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=204'>205</a>\u001b[0m \u001b[39melif\u001b[39;00m learning_mode \u001b[39m==\u001b[39m LearningMode\u001b[39m.\u001b[39mNEWTON:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=205'>206</a>\u001b[0m     model_weights, model_biases \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_map(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=206'>207</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m weights, biases: \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=207'>208</a>\u001b[0m             newtons(weights, biases, batch_data, batch_target),\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=208'>209</a>\u001b[0m         model_weights,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=209'>210</a>\u001b[0m         model_biases,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=210'>211</a>\u001b[0m     )\n",
      "\u001b[1;32m/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39massert\u001b[39;00m weights\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m, weights\u001b[39m.\u001b[39mshape\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=112'>113</a>\u001b[0m \u001b[39massert\u001b[39;00m biases\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, weights\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=114'>115</a>\u001b[0m \u001b[39massert\u001b[39;00m batch_data\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, batch_data\u001b[39m.\u001b[39mshape\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=115'>116</a>\u001b[0m \u001b[39massert\u001b[39;00m batch_target\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, batch_target\u001b[39m.\u001b[39mshape\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bcn-c033.server.mila.quebec/home/mila/g/gagnonju/Marg-Li-CoT/with_trl/scratchpad/jax_iris.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=117'>118</a>\u001b[0m new_weights \u001b[39m=\u001b[39m weights \u001b[39m-\u001b[39m lr \u001b[39m*\u001b[39m grad_w(batch_data, batch_target, weights, biases)[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: (10, 64)"
     ]
    }
   ],
   "source": [
    "class CVSets(enum.Enum):\n",
    "    TRAIN = 0\n",
    "    VALID = 1\n",
    "\n",
    "\n",
    "class LearningMode(enum.Enum):\n",
    "    GRADIENT_DESCENT = 0\n",
    "    NEWTON = 1\n",
    "\n",
    "\n",
    "def cross_entropy_fn(batch_data, batch_target, model_fn, model_weights, model_biases):\n",
    "    data = batch_data\n",
    "    print(f\"{batch_target.shape = }\")\n",
    "    target = jnp.expand_dims(batch_target, -1)\n",
    "\n",
    "    logits = model_fn(data, model_weights, model_biases)\n",
    "    log_softmax = jax.nn.log_softmax(logits)\n",
    "\n",
    "    print(f\"{log_softmax.shape = }\")\n",
    "    print(f\"{target.shape = }\")\n",
    "    loss = - jnp.take_along_axis(log_softmax, target, axis=-1)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    return loss, logits\n",
    "\n",
    "\n",
    "def collate_fn(uncollated):\n",
    "    keys = uncollated[0].keys()\n",
    "    output = {}\n",
    "    for key in keys:\n",
    "        output_array = []\n",
    "        for entry in uncollated:\n",
    "            output_array.append(entry[key])    \n",
    "        output[key] = jnp.stack(output_array)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class Digits(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        assert isinstance(data, dict), type(data).mro()\n",
    "        assert isinstance(data[\"data\"], np.ndarray), type(data).mro()\n",
    "        self._data = data\n",
    "\n",
    "    def __getitem__(self, *args, **kwargs):\n",
    "        return {\n",
    "            k: v.__getitem__(*args, **kwargs) \n",
    "            for k, v in self._data.items()\n",
    "        }\n",
    "\n",
    "    def __len__(self, ):\n",
    "        return len(self._data[\"data\"])\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def model_fn(x, model_weights, model_biases):\n",
    "    return x @ model_weights + model_biases\n",
    "\n",
    "\n",
    "vmap_in_axes = [0, 0, None, None]\n",
    "vmap_out_axes = 0\n",
    "\n",
    "DO_VMAP = True\n",
    "\n",
    "def maybe_vmap(fun, *args, **kwargs):\n",
    "    \n",
    "    if DO_VMAP:\n",
    "        return jax.vmap(fun, *args, **kwargs)\n",
    "    else:\n",
    "        return fun\n",
    "\n",
    "print(\"grad_w\")\n",
    "grad_w = maybe_vmap(\n",
    "    jax.grad(\n",
    "    fun=lambda batch_data, batch_target, weights, biases: \n",
    "        cross_entropy_fn(\n",
    "            batch_data,\n",
    "            batch_target,\n",
    "            model_fn, \n",
    "            weights,\n",
    "            biases,\n",
    "        ),\n",
    "    argnums=2,\n",
    "    has_aux=True,\n",
    "), \n",
    "in_axes=vmap_in_axes,\n",
    "out_axes=vmap_out_axes,\n",
    ")\n",
    "\n",
    "print(\"grad_b\")\n",
    "grad_b = maybe_vmap(\n",
    "    jax.grad(\n",
    "        fun=lambda batch_data, batch_target, weights, biases: \n",
    "            cross_entropy_fn(\n",
    "                batch_data,\n",
    "                batch_target,\n",
    "                model_fn, \n",
    "                weights,\n",
    "                biases,\n",
    "            ),\n",
    "        argnums=3,\n",
    "        has_aux=True,\n",
    "), \n",
    "out_axes=vmap_out_axes,\n",
    "in_axes=vmap_in_axes,\n",
    ")\n",
    "\n",
    "grad_w = grad_w\n",
    "grad_b = grad_b\n",
    "\n",
    "def grad_desc(weights, biases, batch_data, batch_target, lr):\n",
    "    assert weights.ndim == 2, weights.shape\n",
    "    assert biases.ndim == 1, weights.shape\n",
    "\n",
    "    assert batch_data.ndim == 1, batch_data.shape\n",
    "    assert batch_target.ndim == 0, batch_target.shape\n",
    "\n",
    "    vmap_grad_w = grad_w(batch_data, batch_target, weights, biases)[0]\n",
    "    vmap_grad_b = grad_b(batch_data, batch_target, weights, biases)[0]\n",
    "\n",
    "    new_weights = weights - lr * vmap_grad_w\n",
    "    new_biases = biases - lr * vmap_grad_b\n",
    "\n",
    "    assert new_weights.ndim == 2, new_weights.shape\n",
    "    assert new_biases.ndim == 1, new_biases.shape\n",
    "\n",
    "    assert new_weights.shape\n",
    "    assert new_biases.shape\n",
    "\n",
    "    return new_weights, new_biases\n",
    "\n",
    "# hessian_w = jax.hessian(\n",
    "#     fun=lambda batch_data, batch_target, weights, biases: \n",
    "#         cross_entropy_fn(\n",
    "#             batch_data, \n",
    "#             batch_target,\n",
    "#             model_fn, \n",
    "#             weights,\n",
    "#             biases,\n",
    "#         ),\n",
    "#     argnums=3,\n",
    "#     has_aux=True,\n",
    "# )\n",
    "\n",
    "# hessian_b = jax.hessian(\n",
    "#     fun=lambda batch_data, batch_target, weights, biases: \n",
    "#         cross_entropy_fn(\n",
    "#             batch_data, \n",
    "#             batch_target,\n",
    "#             model_fn, \n",
    "#             weights,\n",
    "#             biases,\n",
    "#         ),\n",
    "#     argnums=4,\n",
    "#     has_aux=True,\n",
    "# )\n",
    "\n",
    "\n",
    "# def newtons(weights, biases, batch_data, batch_target):\n",
    "#     val_hessian_w = hessian_w(batch_data, batch_target, weights, biases)[0]\n",
    "#     val_hessian_b = hessian_b(batch_data, batch_target, weights, biases)[0]\n",
    "    \n",
    "#     inv_hessian_w = jnp.linalg.inv(val_hessian_w)\n",
    "#     inv_hessian_b = jnp.linalg.inv(val_hessian_b)\n",
    "\n",
    "#     new_weights = weights - inv_hessian_w @ grad_w(batch_data, batch_target, weights, biases)[0]\n",
    "#     new_biases  = biases  - inv_hessian_b @ grad_b(batch_data, batch_target, weights, biases)[0]\n",
    "\n",
    "#     return new_weights, new_biases\n",
    "\n",
    "\n",
    "def step(*, batch_data, batch_target, model_weights, model_biases, model_fn, cv_set, lr, learning_mode):\n",
    "    print(\n",
    "        f\"loss comp: \"\n",
    "        f\"\\n\\t - {vmap_in_axes = } \"\n",
    "        f\"\\n\\t - {batch_data.shape = } \"\n",
    "        f\"\\n\\t - {batch_target.shape = } \"\n",
    "        f\"\\n\\t - {cv_set = }\"\n",
    "    )\n",
    "\n",
    "    loss, logits = maybe_vmap(\n",
    "        lambda batch_data, batch_target, weights, biases: \n",
    "            cross_entropy_fn(\n",
    "                batch_data,\n",
    "                batch_target,\n",
    "                model_fn, \n",
    "                weights,\n",
    "                biases,\n",
    "            ),\n",
    "        in_axes=vmap_in_axes,\n",
    "        out_axes=0,\n",
    "    )(batch_data, batch_target, model_weights, model_biases)\n",
    "\n",
    "    accuracy = (logits.argmax(-1) == batch_target).mean()\n",
    "    \n",
    "    if cv_set == CVSets.TRAIN:\n",
    "        if learning_mode == LearningMode.GRADIENT_DESCENT:\n",
    "\n",
    "            print(\"Grad Desc:\")\n",
    "            model_weights, model_biases = jax.tree_map(\n",
    "                lambda w, b: grad_desc(w, b, batch_data, batch_target, lr),\n",
    "                model_weights,\n",
    "                model_biases,\n",
    "            )\n",
    "\n",
    "        elif learning_mode == LearningMode.NEWTON:\n",
    "            model_weights, model_biases = jax.tree_map(\n",
    "                lambda weights, biases: \n",
    "                    newtons(weights, biases, batch_data, batch_target),\n",
    "                model_weights,\n",
    "                model_biases,\n",
    "            )\n",
    "\n",
    "    return loss, dict(accuracy=accuracy), model_weights, model_biases\n",
    "\n",
    "\n",
    "def train():\n",
    "    NUM_EPOCHS = 5\n",
    "    LEARNING_RATE = 0.1\n",
    "    LEARNING_MODE = LearningMode.GRADIENT_DESCENT # LearningMode.NEWTON # \n",
    "    PRNG_KEY = jax.random.PRNGKey(0)\n",
    "\n",
    "    print(\"Loading digits.\")\n",
    "    digits = sklearn.datasets.load_digits()\n",
    "    print(\"Done loading digits.\")\n",
    "\n",
    "    delim = int(len(digits.data) * .8)\n",
    "    train_data = digits.data[:delim]\n",
    "    std = np.std(train_data, axis=0)\n",
    "    std[std == 0] = 1\n",
    "\n",
    "    mean = np.mean(train_data, axis=0)\n",
    "    train_data -= mean\n",
    "    train_data /= std\n",
    "    valid_data = digits.data[delim:]\n",
    "    valid_data -= mean\n",
    "    valid_data /= std\n",
    "\n",
    "    datasets = {\n",
    "        CVSets.TRAIN: Digits(dict(data=train_data, target=digits.target[:delim])),\n",
    "        CVSets.VALID: Digits(dict(data=valid_data, target=digits.target[delim:])),\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        cv_set: torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=10,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        \n",
    "        for cv_set, dataset\n",
    "        in datasets.items()\n",
    "    }\n",
    "\n",
    "    model_weights = jax.random.uniform(PRNG_KEY, shape=(64, 10,))\n",
    "    model_biases = jax.random.uniform(PRNG_KEY, shape=(10,))\n",
    "    \n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for cv_set in [CVSets.TRAIN, CVSets.VALID]:\n",
    "            all_metrics = collections.defaultdict(list)\n",
    "            for batch in tqdm.tqdm(dataloaders[cv_set]):\n",
    "                print(\"\\nStep:\")\n",
    "                loss, metrics, model_weights, model_biases = step(\n",
    "                    batch_data=batch[\"data\"],\n",
    "                    batch_target=batch[\"target\"],\n",
    "                    cv_set=cv_set,\n",
    "                    model_fn=model_fn,\n",
    "                    model_weights=model_weights,\n",
    "                    model_biases=model_biases,\n",
    "                    learning_mode=LEARNING_MODE,\n",
    "                    lr=LEARNING_RATE,\n",
    "                )\n",
    "                assert model_weights.ndim == 2, model_weights.ndim\n",
    "                assert model_biases.ndim == 1, model_biases.ndim\n",
    "\n",
    "                for k, v in metrics.items():\n",
    "                    all_metrics[k].append(v)\n",
    "            \n",
    "            for k, v in all_metrics.items():\n",
    "                rich.print(f\"[bold green]({cv_set})[/] Epoch {epoch}: [bold blue]{k.title()}:[/] {np.mean(v):0.2%}\")\n",
    "\n",
    "train()\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.ones(shape=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
