name: acc_maintain=${acc_maintain}_model_name=${model.model_name}_num_beams=${generation_kwargs.num_beams}
eval_every: 0
eval_subset_size: 100
task_name: main
dataset_name: gsm8k
just_metrics: false
mini_batch_size: 1
generation_batch_size: 1
inference_batch_size: 1
generation_kwargs:
  min_new_tokens: 1
  max_new_tokens: 100
  temperature: 1.0
  use_cache: true
  low_memory: false
  num_beams: 25
  num_return_sequences: ${generation_kwargs.num_beams}
  do_sample: true
inference_generation_kwargs:
  do_sample: false
  min_new_tokens: 1
  num_beams: 1
  num_return_sequences: 1
  repetition_penalty: 1
  temperature: 1.0
  use_cache: true
  max_new_tokens: 100
model:
  model_name: susnato/phi-2
peft_config:
  bias: none
  inference_mode: false
  lora_dropout: 0.0
  lora_alpha: 128
  r: 128
  task_type: null
ppo_config:
  kl_penalty: kl
  ratio_threshold: 10
  learning_rate: 1.0e-05
  adap_kl_ctrl: false
  init_kl_coef: 0.2
  gradient_accumulation_steps: 2
acc_maintain:
  class_name: MaxLevelGlobalAvgAcc
  limit_to_respect: 0.5
curriculum_schedule: ???
tok_max_query_length: 115
tok_max_answer_length: null
tok_max_total_length: 290
answer_only_max_length: 15
use_few_shots: true
few_shot_qty: 5
wandb_project: rl_${dataset_name}
use_peft: true
batch_size: 1
max_epochs: 10
no_training: false
use_curriculum: false
inspect_indices: false
answer_only: false
answer_only_path: null
value_pretrain_epochs: null
precision: float32
float32_precision_generation: highest
float32_precision_forward_backward: highest
peft_do_all_lin_layers: false
reward_type: exact_match
start_eval: false
arithmetic_dataset_root_folder_dir: /home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic/
