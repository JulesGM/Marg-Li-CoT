{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset gsm8k (/home/mila/g/gagnonju/.cache/huggingface/datasets/gsm8k/main/1.1.0/37bfb08b1d4fcbb01f06b03d9e1ef5f1fcbd4d3af3d08842c50d7305091285ba)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"gsm8k\", \"main\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"google/flan-t5-xxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_questions = [len(tokenizer(x[\"question\"])[\"input_ids\"]) for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319\n",
      "1233\n",
      "93.5%\n"
     ]
    }
   ],
   "source": [
    "print(len(lengths_questions))\n",
    "print(len([x for x in lengths_questions if x < 100]))\n",
    "print(f\"{len([x for x in lengths_questions if x < 100]) / len(lengths_questions):0.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319\n",
      "1264\n",
      "95.8%\n"
     ]
    }
   ],
   "source": [
    "lengths_answers = sorted([len(tokenizer(x[\"answer\"])[\"input_ids\"]) for x in dataset])\n",
    "print(len(lengths_answers))\n",
    "limit = 192\n",
    "\n",
    "print(len([x for x in lengths_answers if x < limit]))\n",
    "print(f\"{len([x for x in lengths_answers if x < limit]) / len(lengths_answers):0.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [len(tokenizer(x[\"question\"])[\"input_ids\"]) for x in dataset]\n",
    "answers   = [len(tokenizer(x[\"answer\"  ])[\"input_ids\"]) for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.6%\n"
     ]
    }
   ],
   "source": [
    "max_len_questions = 83\n",
    "max_len_answers   = 192\n",
    "print(f\"{len([None for q, a in zip(questions, answers) if q < max_len_questions and a < max_len_answers]) / len(dataset):0.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper: 96.00%,\n",
      "max_encoder_l: 112,\n",
      "max_decoder_l: 192,\n",
      "max_squared_sum_l: 45889\n",
      "92.9%\n"
     ]
    }
   ],
   "source": [
    "# upper = pow(0.9223, 1 / 3)\n",
    "upper = .97\n",
    "assert len(questions) == len(answers)\n",
    "total_l = len(questions)\n",
    "\n",
    "limit_pos = int(upper * total_l)\n",
    "\n",
    "max_encoder_l = sorted(questions)[limit_pos]\n",
    "max_decoder_l = sorted(answers)[limit_pos]\n",
    "max_squared_sum_l = sorted([(i ** 2 + j ** 2, i, j) for i, j in zip(questions, answers)], key=lambda x: x[0])[limit_pos][0]\n",
    "print(\n",
    "    f\"upper: {upper:0.2%},\\n\"\n",
    "    f\"max_encoder_l: {max_encoder_l},\\n\"\n",
    "    f\"max_decoder_l: {max_decoder_l},\\n\"\n",
    "    f\"max_squared_sum_l: {max_squared_sum_l}\"\n",
    ")\n",
    "filtered = [(i, j) for i, j in zip(questions, answers) if i < max_encoder_l and j < max_decoder_l and i ** 2 + j ** 2 < max_squared_sum_l]\n",
    "print(f\"{len(filtered) / len(dataset):0.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mila/g/gagnonju/.cache/huggingface/datasets/gsm8k/main/1.1.0/37bfb08b1d4fcbb01f06b03d9e1ef5f1fcbd4d3af3d08842c50d7305091285ba/cache-2e7168e5481a8abc.arrow\n"
     ]
    }
   ],
   "source": [
    "filtered_ds = dataset.filter(lambda x: len(tokenizer(x[\"question\"])[\"input_ids\"]) ** 2 + len(tokenizer(x[\"answer\"])[\"input_ids\"]) ** 2 < 43205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95.4%'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{len(filtered_ds) / len(dataset):0.1%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5df931a2f82070a33ae1c20bff26f0f27f06960f553260770733988e82cce89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
