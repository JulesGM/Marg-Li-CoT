{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/g/gagnonju/marglicot/light_eval_tests/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import collections\n",
    "import contextlib\n",
    "import copy\n",
    "import dataclasses as dc\n",
    "import datetime\n",
    "import enum\n",
    "import functools\n",
    "import gc\n",
    "import hashlib\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from typing import Any\n",
    "\n",
    "# Third-party imports\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import rich\n",
    "import rich.console\n",
    "import rich.table\n",
    "import tqdm\n",
    "from ast import literal_eval\n",
    "from IPython.display import display, Markdown\n",
    "import more_itertools as mit\n",
    "import itertools as it\n",
    "\n",
    "os.environ[\"OPENINSTRUCT_PARSE_LATEX_BACKEND\"] = \"lark\" \n",
    "\n",
    "sys.path.append(\"/home/mila/g/gagnonju/marglicot/with_open-instruct/open-instruct\")\n",
    "from open_instruct.math_utils import (\n",
    "    last_boxed_only_string,\n",
    "    remove_boxed,\n",
    "    get_unnormalized_answer,\n",
    "    normalize_final_answer,\n",
    "    is_equiv,\n",
    "    hendrycks_is_equiv\n",
    ")\n",
    "\n",
    "\n",
    "def md_print(text):\n",
    "    display(Markdown(text))\n",
    "\n",
    "\n",
    "# Make Pandas display better.\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pl.Config(fmt_str_lengths=500, tbl_width_chars=10000, tbl_rows=100, tbl_cell_alignment=\"LEFT\")\n",
    "\n",
    "\n",
    "\n",
    "class Mode(enum.Enum):\n",
    "    gsm8k = \"gsm8k\"\n",
    "    math = \"math\"\n",
    "\n",
    "class LearningType(enum.Enum):\n",
    "    sft = \"sft\"\n",
    "    rejection = \"rejection\"\n",
    "    zero_shot = \"zero_shot\"\n",
    "    few_shot = \"few_shot\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the paths of all of the per epoch saves\n",
    "We need all the save paths.\n",
    "- We find all of the saves by looking for all of the safetensors files\n",
    "- There is one save per epoch, & the save directories are .../model/checkpoint_name.safetensors, so we call .parent.parent to get the run directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We found 388 saves."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAVE_DIRECTORY = \"~/scratch/marglicot_saves/sft_saves\"\n",
    "CHECKPOINT_GLOB_PATTERN = \"**/*.safetensors\"\n",
    "\n",
    "paths_saves_per_checkpoint = []\n",
    "for x in pathlib.Path(SAVE_DIRECTORY).expanduser().glob(CHECKPOINT_GLOB_PATTERN):\n",
    "    paths_saves_per_checkpoint.append(x.parent.parent)\n",
    "display(Markdown(f\"We found {len(paths_saves_per_checkpoint)} saves.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralize paths per run, sorting by creation time.\n",
    "We need to know which runs exist. We need to know:\n",
    "- When they were created.\n",
    "- How many epochs (checkpoints) they have.\n",
    "\n",
    "We will then need to plot the accuracy per epoch for a selection of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We found **29** runs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## >> Runs to **creation date** and **number of checkpoints**:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                      run  num_paths        creation_time  creation_time_raw\n",
      "0                 /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_001/ao_gsm8k_smollm2_1.7B-2025-03-10_01-28-43          2  2025-03-10 21:55:46       1.741658e+09\n",
      "1                /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_001/cot_gsm8k_smollm2_1.7B-2025-03-10_01-28-46          7  2025-03-10 21:55:46       1.741658e+09\n",
      "2                  /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_001/ao_math_smollm2_1.7B-2025-03-10_01-28-46          2  2025-03-10 21:55:46       1.741658e+09\n",
      "3                 /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_001/cot_math_smollm2_1.7B-2025-03-10_01-46-43          7  2025-03-10 21:55:46       1.741658e+09\n",
      "4                 /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_001/cot_math_smollm2_1.7B-2025-03-10_01-49-58          7  2025-03-10 21:55:46       1.741658e+09\n",
      "5                /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_00001/ao_math_smollm2_1.7B-2025-03-10_01-31-43         10  2025-03-10 21:55:46       1.741658e+09\n",
      "6              /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_00001/cot_gsm8k_smollm2_1.7B-2025-03-10_01-31-43          7  2025-03-10 21:55:46       1.741658e+09\n",
      "7               /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_00001/ao_gsm8k_smollm2_1.7B-2025-03-10_01-31-47         10  2025-03-10 21:55:46       1.741658e+09\n",
      "8    /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_0005/checkpoints/ao_gsm8k_smollm2_1.7B-2025-03-10_23-32-03         30  2025-03-15 23:27:19       1.742096e+09\n",
      "9   /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/0_0005/checkpoints/cot_gsm8k_smollm2_1.7B-2025-03-10_23-32-14         30  2025-03-15 23:27:19       1.742096e+09\n",
      "10                     /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B-2025-03-16_00-02-01         12  2025-03-16 01:58:54       1.742105e+09\n",
      "11             /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_00001-2025-03-16_00-02-01         30  2025-03-16 04:52:01       1.742115e+09\n",
      "12            /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000025-2025-03-16_02-39-20         30  2025-03-16 07:36:56       1.742125e+09\n",
      "14           /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_00005_5-2025-03-16_19-34-20          5  2025-03-16 20:23:54       1.742171e+09\n",
      "13         /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000025_30-2025-03-16_19-25-20         21  2025-03-16 22:55:15       1.742180e+09\n",
      "15         /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_30-2025-03-16_19-40-20         20  2025-03-16 23:00:10       1.742180e+09\n",
      "16          /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_5-2025-03-16_19-43-20         20  2025-03-16 23:00:27       1.742180e+09\n",
      "17           /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_00025_5-2025-03-16_23-10-55          5  2025-03-17 00:00:49       1.742184e+09\n",
      "18            /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_0001_5-2025-03-16_23-10-55          5  2025-03-17 00:00:51       1.742184e+09\n",
      "19          /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_5-2025-03-16_23-10-55         13  2025-03-17 01:19:41       1.742189e+09\n",
      "20           /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_0001_15-2025-03-17_00-51-17          5  2025-03-17 01:41:06       1.742190e+09\n",
      "22          /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_5-2025-03-17_01-26-01          5  2025-03-17 02:15:20       1.742192e+09\n",
      "21         /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_15-2025-03-17_01-26-01         15  2025-03-17 03:54:50       1.742198e+09\n",
      "24           /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21         15  2025-04-06 13:23:50       1.743960e+09\n",
      "23            /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21         15  2025-04-06 13:29:53       1.743961e+09\n",
      "25            /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21         15  2025-04-06 13:35:10       1.743961e+09\n",
      "26              /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58         15  2025-04-13 13:48:41       1.744567e+09\n",
      "27             /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58         15  2025-04-13 13:49:53       1.744567e+09\n",
      "28             /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58         15  2025-04-13 13:52:51       1.744567e+09\n"
     ]
    }
   ],
   "source": [
    "by_run = collections.defaultdict(list)\n",
    "for path in paths_saves_per_checkpoint:\n",
    "    by_run[path.parent].append(path)\n",
    "\n",
    "md_print(f\"We found **{len(by_run)}** runs.\")\n",
    "\n",
    "high_level_info = []\n",
    "for run, paths in by_run.items():\n",
    "    high_level_info.append({\n",
    "        \"run\": run,\n",
    "        \"num_paths\": len(paths),\n",
    "        \"creation_time\": datetime.datetime.fromtimestamp(run.stat().st_ctime).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"creation_time_raw\": run.stat().st_ctime\n",
    "    })\n",
    "\n",
    "high_level_info = pd.DataFrame(high_level_info)\n",
    "high_level_info = high_level_info.sort_values('creation_time_raw', ascending=True)\n",
    "\n",
    "\n",
    "md_print(\"## >> Runs to **creation date** and **number of checkpoints**:\")\n",
    "print(high_level_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the runs that we care about\n",
    "We only care about the runs that happened on the **2025-04-06**.\n",
    "\n",
    "They are the latest runs at the time of writing.\n",
    "\n",
    "We extract those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## >> Filtered runs to **creation date** and **number of checkpoints**:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Found **6** runs from **2025-03-17**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                               run  num_paths        creation_time  creation_time_raw\n",
      "17    /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_00025_5-2025-03-16_23-10-55          5  2025-03-17 00:00:49       1.742184e+09\n",
      "18     /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_0001_5-2025-03-16_23-10-55          5  2025-03-17 00:00:51       1.742184e+09\n",
      "19   /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_5-2025-03-16_23-10-55         13  2025-03-17 01:19:41       1.742189e+09\n",
      "20    /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_0001_15-2025-03-17_00-51-17          5  2025-03-17 01:41:06       1.742190e+09\n",
      "22   /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_5-2025-03-17_01-26-01          5  2025-03-17 02:15:20       1.742192e+09\n",
      "21  /home/mila/g/gagnonju/scratch/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_15-2025-03-17_01-26-01         15  2025-03-17 03:54:50       1.742198e+09\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color: red; font-weight: bold; font-size: 1.2em;'>⚠️ Warning: 2025-03-17 is not the last date. The last date is 2025-04-13</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter runs from 2025-04-06\n",
    "DATE_OF_INTEREST = \"2025-03-17\"\n",
    "# DATE_OF_INTEREST = \"2025-04-06\"\n",
    "# DATE_OF_INTEREST = \"2025-04-13\"\n",
    "\n",
    "filtered_runs = high_level_info[high_level_info['creation_time'].str.contains(DATE_OF_INTEREST)]\n",
    "display(Markdown(\"## >> Filtered runs to **creation date** and **number of checkpoints**:\"))\n",
    "md_print(f\"Found **{len(filtered_runs)}** runs from **{DATE_OF_INTEREST}**\")\n",
    "print(filtered_runs)\n",
    "\n",
    "# Get the last date from all runs\n",
    "last_date = high_level_info['creation_time'].str.split(' ').str[0].max()\n",
    "\n",
    "# Check if the date of interest is the last date\n",
    "if DATE_OF_INTEREST != last_date:\n",
    "    md_print(f\"<span style='color: red; font-weight: bold; font-size: 1.2em;'>⚠️ Warning: {DATE_OF_INTEREST} is not the last date. The last date is {last_date}</span>\")\n",
    "else:\n",
    "    md_print(f\"✅ {DATE_OF_INTEREST} is the last date.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if we ran inference on all of the filtered runs\n",
    "To do that we need to look for all of the inference outputs in the all_eval_outputs_important directory.\n",
    "\n",
    "We find the paths through pattern matching in the path names of the inference outputs directories.\n",
    "\n",
    "- We find all eval outputs by finding all of the .parquet files in the all_eval_outputs_important directory.\n",
    "- We extract the associated meta_info.json files, which contain the path to the associated run checkpoint directory.\n",
    "- We make a join on the filtered runs and the extracted paths to get the runs that we did inference on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7f27179c0360>, {PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'): defaultdict(<class 'list'>, {0: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'})], 4: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_001_15_6578578', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_001_15-2025-04-13_02-41-58', 'wandb_run_id': 'kfaa196f5', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/kfaa196f5'})]}), PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'): defaultdict(<class 'list'>, {0: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'})], 4: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 5e-05, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_00005_15_6529775', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_00005_15-2025-04-06_02-03-21', 'wandb_run_id': 'of993c066', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/of993c066'})]}), PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'): defaultdict(<class 'list'>, {0: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'})], 4: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.01, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_01_15_6578577', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_01_15-2025-04-13_02-41-58', 'wandb_run_id': 'a0265901b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/a0265901b'})]}), PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'): defaultdict(<class 'list'>, {0: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'})], 4: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0005_15_6529777', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0005_15-2025-04-06_02-03-21', 'wandb_run_id': 'm8e0d0a3b', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/m8e0d0a3b'})]}), PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'): defaultdict(<class 'list'>, {0: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'})], 4: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.005, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_005_15_6578579', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_005_15-2025-04-13_02-41-58', 'wandb_run_id': 'se671c5c9', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/se671c5c9'})]}), PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'): defaultdict(<class 'list'>, {0: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/0_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'})], 4: [MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_6_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_6_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 6, 'global_step': 48573, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_0_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_0_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 0, 'global_step': 6939, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_12_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_12_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 12, 'global_step': 90207, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_10_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_10_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 10, 'global_step': 76329, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_2_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_2_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 2, 'global_step': 20817, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_8_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_8_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 8, 'global_step': 62451, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_4_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_4_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 4, 'global_step': 34695, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_5_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_5_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 5, 'global_step': 41634, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_9_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_9_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 9, 'global_step': 69390, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_7_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_7_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 7, 'global_step': 55512, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_3_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_3_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 3, 'global_step': 27756, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_11_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_11_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 11, 'global_step': 83268, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_13_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_13_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 13, 'global_step': 97146, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_1_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_1_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 1, 'global_step': 13878, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'}), MetaInfo(inference_outputs_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/details/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_14_model'), save_path_from_json=PosixPath('/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21'), results_path=PosixPath('/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/sft_outputs_math/4_shot/results/_home_mila_g_gagnonju_scratch_marglicot_saves_sft_saves_cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21_14_model'), meta_config={'cfg': {'batch_table_print_qty': 4, 'begin_with_eval': True, 'data_directory': '/home/mila/g/gagnonju/marglicot/mlc_datasets/arithmetic', 'dataset_choice': 'math', 'extractor_ignore_one_line': False, 'filter_out_bad': True, 'gen_kwargs': {'do_sample': False, 'max_length': 512, 'min_new_tokens': 1, 'repetition_penalty': 1, 'temperature': 1, 'use_cache': True}, 'is_instruct_model': True, 'just_device_map': False, 'learning_rate': 0.0001, 'lm_mode': 'causal_full', 'mask_query': False, 'max_num_epochs': 15, 'model_name_or_path': 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'n_batches_predict_train': 100, 'output_type': {'enum': 'chain_of_thought_then_answer', 'eval_batch_size': 1, 'max_length': 512, 'train_batch_size': 1}, 'peft_config_dict': {'bias': 'none', 'inference_mode': False, 'lora_alpha': 256, 'lora_dropout': 0, 'r': 256, 'task_type': 'CAUSAL_LM'}, 'peft_do_all_lin_layers': False, 'precision': 'torch.bfloat16', 'predict_qty_print': 2, 'qty_eval_small': 5, 'run_name': 'cot_math_smollm2_1.7B_0_0001_15_6529780', 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves', 'stop_at_line_return': False, 'subset_data': False, 'test_mode': False, 'tok_max_query_length': None, 'tok_max_total_length': 768, 'use_peft': False, 'use_workers': False, 'wandb_entity': 'julesgm', 'wandb_project_name': 'sft_arithmetic'}, 'epoch': 14, 'global_step': 104085, 'save_path': '/network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_math_smollm2_1.7B_0_0001_15-2025-04-06_02-03-21', 'wandb_run_id': 'gd43ef43f', 'wandb_url': 'https://wandb.ai/julesgm/sft_arithmetic/runs/gd43ef43f'})]})})\n",
      "\n",
      "<class 'pathlib.PosixPath'> /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_00025_5-2025-03-16_23-10-55\n",
      "Run /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_00025_5-2025-03-16_23-10-55 not found in run_path_to_meta\n",
      "<class 'pathlib.PosixPath'> /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_0001_5-2025-03-16_23-10-55\n",
      "Run /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_0001_5-2025-03-16_23-10-55 not found in run_path_to_meta\n",
      "<class 'pathlib.PosixPath'> /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_5-2025-03-16_23-10-55\n",
      "Run /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_5-2025-03-16_23-10-55 not found in run_path_to_meta\n",
      "<class 'pathlib.PosixPath'> /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_0001_15-2025-03-17_00-51-17\n",
      "Run /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_0001_15-2025-03-17_00-51-17 not found in run_path_to_meta\n",
      "<class 'pathlib.PosixPath'> /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_5-2025-03-17_01-26-01\n",
      "Run /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_5-2025-03-17_01-26-01 not found in run_path_to_meta\n",
      "<class 'pathlib.PosixPath'> /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_15-2025-03-17_01-26-01\n",
      "Run /network/scratch/g/gagnonju/marglicot_saves/sft_saves/cot_gsm8k_smollm2_1.7B_0_000075_15-2025-03-17_01-26-01 not found in run_path_to_meta\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Found **0** runs with inference outputs out of **6** total filtered runs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Found a total of **0** checkpoints."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODE = Mode.math\n",
    "LEARNING_TYPE = LearningType.sft\n",
    "EVAL_OUTPUTS_DIR = f\"/home/mila/g/gagnonju/marglicot/light_eval_tests/all_eval_outputs_important/{LEARNING_TYPE.value}_outputs_{MODE.value}/\"\n",
    "GLOB_PATTERN = \"**/*.parquet\"\n",
    "MIN_MAX_NUM_EPOCHS = None\n",
    "\n",
    "\n",
    "paths_eval = [\n",
    "    x.parent.parent for x in pathlib.Path(EVAL_OUTPUTS_DIR).glob(GLOB_PATTERN)\n",
    "]\n",
    "\n",
    "@dc.dataclass\n",
    "class MetaInfo:\n",
    "    inference_outputs_path: str | pathlib.Path\n",
    "    save_path_from_json: str | pathlib.Path\n",
    "    results_path: str | pathlib.Path\n",
    "    meta_config: dict[str, Any]\n",
    "\n",
    "########################################################\n",
    "# Extract the info from the Eval Outputs\n",
    "########################################################\n",
    "ckpt_paths: list[MetaInfo] = []\n",
    "for path_eval in paths_eval:\n",
    "    # Replace \"details\" with \"results\" in the path\n",
    "\n",
    "    details_idx = path_eval.parts.index(\"details\")\n",
    "    results_path = pathlib.Path(*(it.chain(path_eval.parts[:details_idx], [\"results\"], path_eval.parts[details_idx + 1:])))\n",
    "    meta_info_path = results_path / \"meta_info.json\"\n",
    "\n",
    "    with open(meta_info_path, \"r\") as f:\n",
    "        meta_info = json.load(f)\n",
    "\n",
    "    run_path = pathlib.Path(meta_info[\"save_path\"]).resolve()\n",
    "    # print(meta_info)\n",
    "    ckpt_paths.append(MetaInfo(\n",
    "        inference_outputs_path=path_eval.resolve(), \n",
    "        save_path_from_json=run_path, \n",
    "        results_path=results_path, \n",
    "        meta_config=meta_info\n",
    "    ))\n",
    "\n",
    "\n",
    "assert len(ckpt_paths) == len(paths_eval)\n",
    "# print(\"\\n\".join([str(x.save_path_from_json) for x in ckpt_paths]))\n",
    "\n",
    "# For each run in filtered_runs, see for which ones we have inference outputs\n",
    "# Create a mapping from run paths to their corresponding MetaInfo objects\n",
    "run_path_to_meta = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "for meta in ckpt_paths:\n",
    "    results_json = json.loads(pathlib.Path(mit.one(meta.results_path.glob(\"**/results*.json\"))).read_text())\n",
    "    n_shots = int(mit.one(results_json[\"versions\"]).rsplit(\"|\")[-1])\n",
    "    effective_few_shots = mit.one(results_json[\"summary_tasks\"].values())[\"effective_few_shots\"]\n",
    "    max_num_epochs = meta.meta_config[\"cfg\"][\"max_num_epochs\"]\n",
    "    if not MIN_MAX_NUM_EPOCHS or (max_num_epochs >= MIN_MAX_NUM_EPOCHS):\n",
    "        run_path_to_meta[meta.save_path_from_json][n_shots].append(meta)\n",
    "\n",
    "print(run_path_to_meta)\n",
    "########################################################\n",
    "# Extract the runs that have inference outputs\n",
    "########################################################\n",
    "filtered_runs_with_outputs = []\n",
    "print()\n",
    "for run in filtered_runs.itertuples():\n",
    "    # Convert the run path to a Path object for comparison\n",
    "    run_path = pathlib.Path(run.run).resolve()\n",
    "    print(type(run_path), run_path)\n",
    "    if run_path in run_path_to_meta:\n",
    "        filtered_runs_with_outputs.append(run_path_to_meta[run_path])\n",
    "    else:\n",
    "        print(f\"Run {run_path} not found in run_path_to_meta\")\n",
    "\n",
    "md_print(f\"Found **{len(filtered_runs_with_outputs)}** runs with inference outputs out of **{len(filtered_runs)}** total filtered runs\")\n",
    "md_print(f\"Found a total of **{len(list(it.chain.from_iterable(filtered_runs_with_outputs)))}** checkpoints.\")\n",
    "for n_shot_to_run in filtered_runs_with_outputs:\n",
    "    for n_shot, run in n_shot_to_run.items():\n",
    "        max_num_epochs = mit.one(set(x.meta_config[\"cfg\"][\"max_num_epochs\"] for x in run))\n",
    "        epochs = sorted(x.meta_config[\"epoch\"] for x in run)\n",
    "        missing = sorted(set(range(max_num_epochs)) - set(epochs))\n",
    "\n",
    "        text_missing = \"Missing epochs: \" + \", \".join(str(x) for x in missing) if missing else \"✅\"\n",
    "\n",
    "        md_print(f\"(n_shot: {n_shot}) Found **{len(run)}** checkpoints of **{max_num_epochs}** expected. {text_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the accuracy for the epochs that we do have, per run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_PLOTS = True\n",
    "if SHOW_PLOTS:\n",
    "    for n_shot_to_run in filtered_runs_with_outputs:\n",
    "        for n_shot, run in n_shot_to_run.items():\n",
    "            by_epoch = {}\n",
    "            learning_rates = set()\n",
    "            for ckpt in run:\n",
    "                results_path = ckpt.results_path\n",
    "                epoch = ckpt.meta_config[\"epoch\"]\n",
    "                # Extract results from this\n",
    "                results_jsons = mit.one(results_path.glob(\"**/results*.json\"))\n",
    "                with open(results_jsons, \"r\") as f:\n",
    "                    parsed = json.load(f)\n",
    "                by_epoch[epoch] = parsed[\"results\"][\"all\"][\"qem\"]\n",
    "                learning_rate = ckpt.meta_config[\"cfg\"][\"learning_rate\"]\n",
    "                learning_rates.add(learning_rate)\n",
    "\n",
    "            # Create a figure for each run\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.figure(figsize=(20, 12), dpi=150)\n",
    "            plt.rcParams.update({'font.size': 16})\n",
    "            plt.title(f\"n_shot: {n_shot}, learning_rate: {mit.one(learning_rates)}\")\n",
    "\n",
    "            by_epoch = dict(sorted(by_epoch.items()))\n",
    "            y = np.array(list(by_epoch.values())) * 100\n",
    "            x = np.array(list(by_epoch.keys())) + 1\n",
    "\n",
    "            # Plot the accuracy for each epoch\n",
    "            plt.plot(x, y, marker='o')\n",
    "            plt.xticks(np.arange(1, x.max() + 1))\n",
    "            plt.yticks(np.arange(int(y.min()), int(y.max()) + 1).tolist() + [y.max()])\n",
    "\n",
    "            # Add labels and title\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We re-compute the the scores with our custom parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import verify\n",
    "import importlib\n",
    "importlib.reload(verify)\n",
    "\n",
    "N_QTY = 100\n",
    "MAX_NUM_EPOCHS = 15 \n",
    "\n",
    "time_spent = verify.FractionTimeSpent()\n",
    "\n",
    "output_data = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "for i, n_shot_to_runs in enumerate(filtered_runs_with_outputs):\n",
    "    for n_shot, runs in n_shot_to_runs.items():\n",
    "        if n_shot == 0:\n",
    "            for run in runs:\n",
    "                if run[\"cfg\"][\"max_num_epochs\"] == MAX_NUM_EPOCHS:\n",
    "                    parquet_path = mit.one(run.inference_outputs_path.glob(\"**/*.parquet\"))\n",
    "                    results = verify.compute_score(parquet_path, mode=verify.Mode.math, time_spent=time_spent, compute_score=True, subset_qty=N_QTY)\n",
    "                    print(results[0].row(0, named=True))\n",
    "                    output_data[i][n_shot].append(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
