{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm8k = datasets.load_dataset(\"gsm8k\", \"main\")\n",
    "t = transformers.AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-1.7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_shot_text(*, gsm8k, tokenizer, N, use_cot, with_last_answer=False):\n",
    "    turns = []\n",
    "\n",
    "    for i, qa in enumerate(pd.DataFrame(gsm8k[\"train\"][:N + 1]).to_dict(orient=\"records\")):\n",
    "        is_last = i == N + 1 - 1\n",
    "        reasoning, answer = qa[\"answer\"].split(\"####\")\n",
    "        turns.append({\"role\": \"user\", \"content\": qa[\"question\"]})\n",
    "\n",
    "        # In the default case, we don't want to add the last answer to the last turn,\n",
    "        # because it's the model's job to generate the answer.\n",
    "        # If with_last_answer is True, we override this behavior.\n",
    "        if with_last_answer or not is_last:\n",
    "\n",
    "            if use_cot:\n",
    "                content = reasoning + \" Answer: \" + answer\n",
    "            else:\n",
    "                content = \"Answer: \" + answer\n",
    "\n",
    "            turns.append({\"role\": \"assistant\", \"content\": content})\n",
    "\n",
    "    return tokenizer.apply_chat_template(\n",
    "        turns, \n",
    "        add_generation_prompt=not with_last_answer, \n",
    "        tokenize=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(n_shot_text(gsm8k=gsm8k, tokenizer=t, N=0, use_cot=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "Answer:  72<|im_end|>\n",
      "<|im_start|>user\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Weng earns 12/60 = $<<12/60=0.2>>0.2 per minute.\n",
      "Working 50 minutes, she earned 0.2 x 50 = $<<0.2*50=10>>10.\n",
      "Answer:  10<|im_end|>\n",
      "<|im_start|>user\n",
      "Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(n_shot_text(gsm8k, t, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
