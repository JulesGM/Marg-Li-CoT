{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A few decisions.\n",
    "\n",
    "###########################################################\n",
    "# Parsing the answer:\n",
    "###########################################################\n",
    "We take the answer by taking the last integer in the answer string.\n",
    "If we don't find an integer, we call word2num on the answer string, to maybe get a word form number.\n",
    "If we don't find a number, in the majority vote case, we ignore that generation in the vote.\n",
    "If none of the generations have a number, we return the default value.\n",
    "Similarily, in the case without majority vote, if we don't find a number, we return the default value.\n",
    "\n",
    "It would be fair to say that we should maybe not use the default value, and just assign the answer as incorrect.\n",
    "We may do that eventually. It would be pretty straightfoward, just change the default value to a stopper object,\n",
    "the comparison with the reference answer would always be false.\n",
    "\n",
    "Floating point numbers:\n",
    "We currently round to the closest integer.\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# Picking questions in the dataset:\n",
    "###########################################################\n",
    "More than 85% of the questions in the ASDiv dataset have a single, integer answer.\n",
    "We only consider those questions, as they make the task of parsing the answer easier.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import collections\n",
    "\n",
    "import importlib\n",
    "import itertools\n",
    "import math\n",
    "import more_itertools\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import xml\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rich\n",
    "import rich.table\n",
    "from text2digits import text2digits\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "import wget\n",
    "\n",
    "import general_utils as utils\n",
    "\n",
    "import asdiv_dataset\n",
    "\n",
    "# importlib.reload(text2digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = datasets.load_dataset(\"gsm8k\", \"main\", split=\"train\")\n",
    "# dataset_test  = datasets.load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
    "\n",
    "# def clean_text(sample):\n",
    "#     return {k: v.replace(\"<<\", \"(\").replace(\">>\", \")\").strip() for k, v in sample.items()}\n",
    "\n",
    "# def split_answer_scratchpad(sample):\n",
    "#     scratchpad, answer = sample[\"answer\"].split(\"####\")\n",
    "#     return {\n",
    "#         \"question\": sample[\"question\"].strip(), \n",
    "#         \"answer\": answer.strip(), \n",
    "#         \"scratchpad\": scratchpad.strip()\n",
    "#     }\n",
    "\n",
    "\n",
    "# dataset_train = dataset_train.map(clean_text).map(split_answer_scratchpad)\n",
    "# dataset_test  = dataset_test .map(clean_text).map(split_answer_scratchpad)\n",
    "\n",
    "# print(dataset_train[0].keys())\n",
    "# print(dataset_test[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = asdiv_dataset.ASDivInteger(cache_path=\"ASDiv.xml\", quiet=False)\n",
    "dataset_test  = dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load the model\n",
    "###############################################################################\n",
    "model_name = \"google/flan-t5-xxl\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "with utils.ctx_timeit(f\"Loading model `{model_name}`\"):\n",
    "    model = transformers.AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "with utils.ctx_timeit(\"Converting model's type\"):\n",
    "    # model_cpu\n",
    "    pass\n",
    "\n",
    "with utils.ctx_timeit(f\"Moving model to GPU\"):\n",
    "    model = model.cuda()\n",
    "\n",
    "rich.print(f\"[bold blue]Model dtype:[/]  {model.dtype}\")\n",
    "devices = collections.Counter(x.device.type for x in model.parameters())\n",
    "rich.print(f\"\\n[bold blue]Model device:[/] {devices}\")\n",
    "\n",
    "assert len(devices) == 1 and \"cuda\" in devices, devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text2digits_ = text2digits.Text2Digits()\n",
    "num_pat = re.compile(r\"\\d+(?:[\\,\\.]\\d+)?\")\n",
    "\n",
    "\n",
    "def deal_with_words(text):\n",
    "    converted = text2digits_.convert(text)\n",
    "    output = num_pat.findall(converted)[-1]\n",
    "    rich.print(\n",
    "        f\"[bold blue]text2digits[/]:\\n\"\n",
    "        f\" \\t - [green]source:[/]    {text}\\n\"\n",
    "        f\" \\t - [green]converted:[/] {converted}\\n\"\n",
    "        f\" \\t - [green]final:[/]     {output}\"\n",
    "    )\n",
    "    return output \n",
    "\n",
    "\n",
    "def split_fn(x):\n",
    "    results = num_pat.findall(x)\n",
    "    if not results:\n",
    "        try:\n",
    "            output = deal_with_words(x)\n",
    "        except ValueError:\n",
    "            output = None\n",
    "\n",
    "        if output is not None:\n",
    "            rich.print(f\"[red]split_fn: no numbers found. Received:[/] `{x}`. Text2Digit worked. Output: `{output}`\")\n",
    "            output = str(output)\n",
    "        else:\n",
    "            rich.print(f\"[red]split_fn: no numbers found. Received:[/] `{x}`\")\n",
    "            output = None\n",
    "    else:\n",
    "        output = results[-1]\n",
    "    return output\n",
    "\n",
    "\n",
    "class ContextGeneration:\n",
    "    \"\"\"\n",
    "    \n",
    "    Namespace\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought_intro = \"Let's think about it step by step. Chain-of-thought:\"\n",
    "    answer_intro           = \"Answer:\"\n",
    "    question_intro         = \"Question:\"\n",
    "\n",
    "    @classmethod\n",
    "    def compose_fewshot_context(cls, dataset, n, with_scratchpad, seed):\n",
    "        \"\"\" \n",
    "        Creates a random few-shot context. Works fine with n = 0.\n",
    "        \"\"\"\n",
    "        rng = random.Random(seed)\n",
    "\n",
    "        indices = rng.sample(range(len(dataset)), n)\n",
    "        output = []\n",
    "        for i in indices:\n",
    "            scratchpad = dataset[i][\"scratchpad\"]\n",
    "            answer = dataset[i][\"answer\"]\n",
    "\n",
    "            assert \"#\" not in scratchpad, scratchpad\n",
    "            assert \"#\" not in answer, answer\n",
    "\n",
    "            text = \"Question: \" + dataset[i][\"question\"]\n",
    "            if with_scratchpad:\n",
    "                text += f\" {cls.chain_of_thought_intro} \" + scratchpad\n",
    "            \n",
    "            text += f\" {cls.answer_intro} \" + answer\n",
    "            output.append(text)\n",
    "\n",
    "        return \" \".join(output)\n",
    "\n",
    "    @classmethod\n",
    "    def collate(cls, inputs, tokenizer, few_shot_context, with_scratchpad):\n",
    "        \"\"\" Collates the inputs and prompts into a single list of strings. \"\"\"\n",
    "\n",
    "        first_context_addition = few_shot_context + f\" {cls.question_intro} \"\n",
    "        final_context_addition = f\" {cls.chain_of_thought_intro} \" if with_scratchpad else f\" {cls.answer_intro} \"\n",
    "\n",
    "        inputs = utils.dict_unzip(inputs)\n",
    "\n",
    "        question_text = [\n",
    "            first_context_addition + question + final_context_addition \n",
    "            for question in inputs[\"question\"]\n",
    "        ]\n",
    "\n",
    "        # rich.print(\n",
    "        #     f\"[bold blue]Question example:[/]\\n\" +\n",
    "        #     random.choice(question_text) \n",
    "        # )\n",
    "\n",
    "        output = tokenizer(\n",
    "            question_text,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ) \n",
    "\n",
    "        output[\"answer\"] = inputs[\"answer\"]\n",
    "        output[\"scratchpad\"] = inputs[\"scratchpad\"]\n",
    "        \n",
    "        return {\n",
    "            k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v \n",
    "            for k, v in output.items()\n",
    "    }\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Dataset stuff\n",
    "###############################################################################\n",
    "def format_output(output):\n",
    "    try:\n",
    "        float_conversion = float(output.replace(\",\", \"\"))\n",
    "    except (ValueError, ArithmeticError) as err:\n",
    "        rich.print(\n",
    "            f\"[bold red]Failed to convert to float. \"\n",
    "            f\"value is:[/] `{output}`, \"\n",
    "            f\"[bold red]error is:[/] {type(err)} {err}\"\n",
    "        )\n",
    "        return \"0\"\n",
    "    \n",
    "    rounding = round(float_conversion)\n",
    "    return str(rounding)\n",
    "\n",
    "\n",
    "def majority_vote(generated, tokenizer, answer_extraction_fn, verbose):\n",
    "    answers = []\n",
    "    for entry in generated:\n",
    "        decoded = tokenizer.decode(entry, skip_special_tokens=True)\n",
    "        output = answer_extraction_fn(decoded)\n",
    "        if output is not None:\n",
    "            answers.append(format_output(output))\n",
    "    \n",
    "    counter = collections.Counter(answers)\n",
    "    if verbose:\n",
    "        print(counter)\n",
    "    if counter:\n",
    "        return counter.most_common(1)[0][0]\n",
    "    else:\n",
    "        return \"0\"\n",
    "\n",
    "\n",
    "def majority_vote_batch(generated, tokenizer, answer_extraction_fn, verbose):\n",
    "    for entry in generated:\n",
    "        yield majority_vote(entry, tokenizer, answer_extraction_fn, verbose)\n",
    "\n",
    "def compare(pred, answ):\n",
    "    return format_output(pred.strip()) == format_output(answ.strip())\n",
    "\n",
    "\n",
    "def run(\n",
    "    *,\n",
    "    shuffle,\n",
    "    verbose,\n",
    "    context,\n",
    "    num_beams,\n",
    "    batch_size,\n",
    "    max_new_tokens,\n",
    "    with_scratchpads,\n",
    "    use_majority_vote,\n",
    "    use_group_beam_search,\n",
    "    generation_extra_kwargs\n",
    "):\n",
    "    args = locals().copy()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset_test,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=batch_size,\n",
    "            collate_fn=lambda inputs: ContextGeneration.collate(\n",
    "                inputs, tokenizer, context, with_scratchpads\n",
    "            )\n",
    "        )\n",
    "\n",
    "        outputs = []\n",
    "        tqdm_obj = tqdm(dataloader)\n",
    "\n",
    "        extra_kwargs = generation_extra_kwargs.copy()\n",
    "        if use_group_beam_search:\n",
    "            extra_kwargs[\"num_beam_groups\"] = num_beams\n",
    "\n",
    "        for batch in tqdm_obj:\n",
    "            output = model.generate(\n",
    "                input_ids            = batch[\"input_ids\"],\n",
    "                attention_mask       = batch[\"attention_mask\"],\n",
    "                num_beams            = num_beams,\n",
    "                num_return_sequences = num_beams if use_majority_vote else 1,\n",
    "                max_new_tokens       = max_new_tokens,\n",
    "                **extra_kwargs\n",
    "            ).reshape(batch_size, num_beams if use_majority_vote else 1, -1)\n",
    "\n",
    "            predictions = list(majority_vote_batch(output, tokenizer, split_fn, verbose))\n",
    "            raw_decoded = [\n",
    "                [tokenizer.decode(x, skip_special_tokens=True) for x in batch_entry] \n",
    "                for batch_entry in output\n",
    "            ]\n",
    "\n",
    "            answer_decoded = [list(map(split_fn, x)) for x in raw_decoded]\n",
    "\n",
    "            if verbose:\n",
    "                for prediction, answer, raw_decoded_entry, answer_decoded, input_text in zip(\n",
    "                    predictions, \n",
    "                    batch[\"answer\"], \n",
    "                    raw_decoded, \n",
    "                    answer_decoded, \n",
    "                    [tokenizer.decode(x) for x in batch[\"input_ids\"]]\n",
    "                ):\n",
    "\n",
    "                    rich.print(\n",
    "                        f\"[bold blue]input_text[/]:      {input_text}\\n\"\n",
    "                        f\"[bold blue]ref_answer[/]:      {answer}\\n\"\n",
    "                        f\"[bold blue]prediction[/]:      {prediction}\\n\"\n",
    "                        # f\"[bold blue]raw_decoded[/]:     {raw_decoded_entry}\\n\"\n",
    "                        f\"[bold blue]answer_decoded[/]:  {answer_decoded}\"\n",
    "                    )\n",
    "                    rich.print(\"[bold blue]Raw Decoded:[/]\")\n",
    "                    for v in raw_decoded_entry:\n",
    "                        rich.print(f\" [bold]-[/] {v}\")\n",
    "\n",
    "            good_bad_preds = [\n",
    "                compare(pred=pred, answ=answ) \n",
    "                for pred, answ in zip(predictions, batch[\"answer\"])\n",
    "            ]\n",
    "\n",
    "            # print([(format_output(a), format_output(b), a, b) for a, b in zip(predictions, batch[\"answer\"])])\n",
    "            # print(good_bad_preds)\n",
    "\n",
    "            outputs.extend(good_bad_preds)\n",
    "            tqdm_obj.set_description(f\"Accuracy: {np.mean(outputs):.1%}\")\n",
    "            \n",
    "        accuracy = np.mean(outputs)\n",
    "\n",
    "        rich.print(args)\n",
    "        rich.print(f\"[bold green]Accuracy, {model.dtype}: {accuracy:.1%}\")\n",
    "\n",
    "\n",
    "verbose = False\n",
    "shuffle = True\n",
    "n_shots = 8\n",
    "num_beams = 8\n",
    "batch_size = 1\n",
    "max_new_tokens = 80\n",
    "with_scratchpads = False\n",
    "use_majority_vote = True\n",
    "use_group_beam_search = False\n",
    "few_shot_context_rng_seed = 42  # Makes sure the context is the same if we want it to stay the same\n",
    "generation_extra_kwargs = dict(repetition_penalty=50.)\n",
    "\n",
    "\n",
    "context = ContextGeneration.compose_fewshot_context(\n",
    "        dataset_train, \n",
    "        n_shots, \n",
    "        with_scratchpads, \n",
    "        few_shot_context_rng_seed,\n",
    "    )\n",
    "\n",
    "\n",
    "rich.print(\n",
    "    f\"[bold blue]Context[/]:\\n\" +\n",
    "    context\n",
    ")\n",
    "\n",
    "\n",
    "run(\n",
    "    shuffle=shuffle,\n",
    "    verbose=verbose,\n",
    "    context=context,\n",
    "    num_beams=num_beams, \n",
    "    batch_size=batch_size, \n",
    "    max_new_tokens=max_new_tokens, \n",
    "    with_scratchpads=with_scratchpads, \n",
    "    use_majority_vote=use_majority_vote, \n",
    "    use_group_beam_search=use_group_beam_search,\n",
    "    generation_extra_kwargs=generation_extra_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASDiv Dataset:\n",
    "\n",
    "- **At a glance**: float32, no context (except let's do this step by step), 8 beams majority vote, fixed number parser.\n",
    "  - **Accuracy**: 37.9%\n",
    "  - **Precision**: float32\n",
    "  - **num_beams**: 8\n",
    "  - **batch_size**: 1\n",
    "  - **max_new_tokens**: 100\n",
    "  - **use_majority_vote**: True\n",
    "  - **use_group_beam_search**: False\n",
    "  - **generation_extra_kwargs**: \n",
    "    - *repetition_penalty*: 50.0\n",
    "    - *context*: ''\n",
    "  - **Notes**: \n",
    "    - For the word outputs, the word2num often doesn't pickup the correct (last) word.\n",
    "    - Uses \"Let's do this step by step\".\n",
    "\n",
    "- **At a glance**: 8 shot (random) context, with scrachpad. The scratchpads are the Formula from the dataset, so they are pretty poor.\n",
    "  - **Accuracy**: 41.2%\n",
    "  - **Precision**: float32\n",
    "  - **num_beams**: 8\n",
    "  - **batch_size**: 1\n",
    "  - **max_new_tokens**: 100\n",
    "  - **use_majority_vote**: True\n",
    "  - **use_group_beam_search**: False\n",
    "  - **generation_extra_kwargs**: \n",
    "    - *repetition_penalty*: 50.0\n",
    "    - *context*: 8 examples in the context, WITH SCRATCHPADS.\n",
    "    - *context seed*: 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5df931a2f82070a33ae1c20bff26f0f27f06960f553260770733988e82cce89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
